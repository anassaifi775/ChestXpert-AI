# ðŸ¤– ChestXpert-AI â€” Chest X-ray Report Generator

This directory contains the **fine-tuned Vision-Language model** used in the **ChestXpert-AI** project for automatic chest X-ray report generation.

---

## ðŸ§  Model Overview

- **Task**: Chest X-ray â†’ Radiology Report Generation  
- **Architecture**: Vision-Language Model (BLIP-based)  
- **Framework**: PyTorch + Hugging Face Transformers  
- **Training Data**: NIH ChestX-ray14 (45GB)  
- **Epochs**: 3  
- **Precision**: FP16 supported  

---

## Model 

![model](huggingface_model.png)

## ðŸ§¬ Model Architecture

Chest X-ray Image
â†“
Vision Encoder (ViT / BLIP)
â†“
Cross-modal Attention
â†“
Text Decoder
â†“
Radiology-style Report


---

## ðŸ“¦ Model Files

best_model/
â”œâ”€â”€ config.json
â”œâ”€â”€ model.safetensors
â”œâ”€â”€ generation_config.json
â”œâ”€â”€ preprocessor_config.json
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ vocab.txt
â”œâ”€â”€ special_tokens_map.json


---

## ðŸ“¥ Model Access

The trained model is hosted on **Hugging Face**:

ðŸ”— **Model Repository**:  
https://huggingface.co/anassaifi8912/chestxray-blip-report-generator

---

## ðŸš€ How to Load the Model

```python
from transformers import BlipProcessor, BlipForConditionalGeneration

processor = BlipProcessor.from_pretrained(
    "anassaifi8912/chestxray-blip-report-generator"
)

model = BlipForConditionalGeneration.from_pretrained(
    "anassaifi8912/chestxray-blip-report-generator"
)

